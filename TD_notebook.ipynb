{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacb756a-3eb0-449d-94ed-0c317dea9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.contrib import tenumerate\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "#torch.cuda.manual_seed(seed)\n",
    "#torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8032e3-f7b4-41ba-83e7-4ae1c1b1bbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/alexandre.nicolas/dataset/sub-01_ses-naming_run-1_eeg.vhdr.fdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pymatreader/utils.py:230: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n",
      "  warn('Complex objects (like classes) are not supported. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 490967  =      0.000 ...   490.967 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-01_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 494517  =      0.000 ...   494.517 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-02_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 491219  =      0.000 ...   491.219 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-02_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 493518  =      0.000 ...   493.518 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-03_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 487617  =      0.000 ...   487.617 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-03_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 493316  =      0.000 ...   493.316 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-04_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 488318  =      0.000 ...   488.318 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-04_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 498419  =      0.000 ...   498.419 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-05_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 493219  =      0.000 ...   493.219 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-05_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 489569  =      0.000 ...   489.569 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-06_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 494868  =      0.000 ...   494.868 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-06_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 490419  =      0.000 ...   490.419 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-07_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 566221  =      0.000 ...   566.221 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-07_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 492870  =      0.000 ...   492.870 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-10_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 498868  =      0.000 ...   498.868 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-10_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 486466  =      0.000 ...   486.466 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-11_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 488669  =      0.000 ...   488.669 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-11_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 493219  =      0.000 ...   493.219 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-12_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 499318  =      0.000 ...   499.318 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-12_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 489819  =      0.000 ...   489.819 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-13_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 493167  =      0.000 ...   493.167 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-13_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 498419  =      0.000 ...   498.419 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-14_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 495168  =      0.000 ...   495.168 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-14_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 496570  =      0.000 ...   496.570 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-16_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 491869  =      0.000 ...   491.869 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-16_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 489666  =      0.000 ...   489.666 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-17_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 492417  =      0.000 ...   492.417 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-17_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 490767  =      0.000 ...   490.767 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-19_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 499418  =      0.000 ...   499.418 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-19_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 496715  =      0.000 ...   496.715 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-21_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 487219  =      0.000 ...   487.219 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-21_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 485418  =      0.000 ...   485.418 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-23_ses-naming_run-1_eeg.vhdr.fdt\n",
      "Reading 0 ... 499267  =      0.000 ...   499.267 secs...\n",
      "Reading /home/alexandre.nicolas/dataset/sub-23_ses-naming_run-2_eeg.vhdr.fdt\n",
      "Reading 0 ... 490068  =      0.000 ...   490.068 secs...\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "n_subject = 17\n",
    "\n",
    "raw = {}\n",
    "for s in np.arange(n_subject):\n",
    "    raw[s] = []\n",
    "\n",
    "for s in np.arange(7):\n",
    "\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-0{s+1}_ses-naming_run-1_eeg.vhdr.set\", preload=True))\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-0{s+1}_ses-naming_run-2_eeg.vhdr.set\", preload=True))\n",
    "\n",
    "for s in np.arange(7,12):\n",
    "        \n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+3}_ses-naming_run-1_eeg.vhdr.set\", preload=True))\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+3}_ses-naming_run-2_eeg.vhdr.set\", preload=True))\n",
    "\n",
    "for s in np.arange(12,14):\n",
    "        \n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+4}_ses-naming_run-1_eeg.vhdr.set\", preload=True))\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+4}_ses-naming_run-2_eeg.vhdr.set\", preload=True))\n",
    "\n",
    "for s in np.arange(14, 15):\n",
    "        \n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+5}_ses-naming_run-1_eeg.vhdr.set\", preload=True))\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+5}_ses-naming_run-2_eeg.vhdr.set\", preload=True))\n",
    "    \n",
    "for s in np.arange(15, 16):\n",
    "        \n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+6}_ses-naming_run-1_eeg.vhdr.set\", preload=True))\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+6}_ses-naming_run-2_eeg.vhdr.set\", preload=True))\n",
    "\n",
    "for s in np.arange(16,17):\n",
    "        \n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+7}_ses-naming_run-1_eeg.vhdr.set\", preload=True))\n",
    "    raw[s].append(mne.io.read_raw_eeglab(f\"dataset/sub-{s+7}_ses-naming_run-2_eeg.vhdr.set\", preload=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd40e673-ef78-4974-8ba7-a2ecdf79f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into float32 to save memory\n",
    "for s in np.arange(n_subject):\n",
    "    raw[s][0]._data = raw[s][0]._data.astype('float32')\n",
    "    raw[s][1]._data = raw[s][1]._data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e562afdf-666e-4476-93d5-b6a221bc51bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n",
      "Used Annotations descriptions: ['ACCORDIO.bmp', 'ACORN.bmp', 'AIRPLANE.bmp', 'ALLIGATO.bmp', 'ANCHOR.bmp', 'APPLE.bmp', 'ARTICHOK.bmp', 'ASHTRAY.bmp', 'ASPARAGU.bmp', 'AXE.bmp', 'BEAR.bmp', 'BEE.bmp', 'BELT.bmp', 'BENCH.bmp', 'BICYCLE.bmp', 'BIRDCAGE.bmp', 'BIRDNEST.bmp', 'BOOT.bmp', 'BOTTLE.bmp', 'BOW.bmp', 'BOWL.bmp', 'BOX.bmp', 'BRAIN.bmp', 'BROOM.bmp', 'BUTTERFL.bmp', 'CANNON.bmp', 'CAP.bmp', 'CAR.bmp', 'CARROT.bmp', 'CAT.bmp', 'CATERPIL.bmp', 'CHEESE.bmp', 'CHICKEN.bmp', 'CHIMNEY.bmp', 'CLOUD.bmp', 'CLOWN.bmp', 'COAT.bmp', 'COMPASS.bmp', 'CORN.bmp', 'COW.bmp', 'CRAB.bmp', 'CROWN.bmp', 'CUP.bmp', 'DEER.bmp', 'DOGHOUSE.bmp', 'DOLPHIN.bmp', 'DONKEY.bmp', 'DOORKNOB.bmp', 'DRAGONFL.bmp', 'DRESS.bmp', 'DRESSER.bmp', 'DUSTPAN.bmp', 'EAGLE.bmp', 'EAR.bmp', 'ELEPHANT.bmp', 'ENVELOPE.bmp', 'EYE.bmp', 'FAN.bmp', 'FAUCET.bmp', 'FEATHER.bmp', 'FISH.bmp', 'FLAG.bmp', 'FLOWER.bmp', 'FORK.bmp', 'FRYINGPA.bmp', 'FUNNEL.bmp', 'GARBAGEC.bmp', 'GLOVE.bmp', 'GORILLA.bmp', 'GUITAR.bmp', 'HAMMOCK.bmp', 'RAY.bmp', 'SCORPION.bmp', 'frenchcr.bmp']\n",
      "Used Annotations descriptions: ['CIGARETT.bmp', 'GLASS.bmp', 'HAMMER.bmp', 'HARMONIC.bmp', 'HARP.bmp', 'HAT.bmp', 'HYENA.bmp', 'KNIFE.bmp', 'LADDER.bmp', 'LADYBUG.bmp', 'LAMP.bmp', 'LEG.bmp', 'LIGHTBUL.bmp', 'LION.bmp', 'LOCK.bmp', 'MICROSCO.bmp', 'MONKEY.bmp', 'MOON.bmp', 'MOTORCYC.bmp', 'MOUNTAIN.bmp', 'NAIL.bmp', 'NAILFILE.bmp', 'NECKLACE.bmp', 'NOSE.bmp', 'OSTRICH.bmp', 'PAINTBRU.bmp', 'PALMTREE.bmp', 'PANTS.bmp', 'PEACOCK.bmp', 'PEAR.bmp', 'PELICAN.bmp', 'PIANO.bmp', 'PICTURE.bmp', 'PIPE.bmp', 'PLIERS.bmp', 'PLUG.bmp', 'POT.bmp', 'RABBIT.bmp', 'RAT.bmp', 'RING.bmp', 'ROCKET.bmp', 'ROOSTER.bmp', 'RULER.bmp', 'SAW.bmp', 'SCREW.bmp', 'SHIRT.bmp', 'SHOE.bmp', 'SKIRT.bmp', 'SKULL.bmp', 'SNAIL.bmp', 'SNAKE.bmp', 'SOCK.bmp', 'SPIDER.bmp', 'SQUIRREL.bmp', 'STOOL.bmp', 'SWAN.bmp', 'SYRINGE.bmp', 'Scale.bmp', 'TELEPHON.bmp', 'TIE.bmp', 'TIGER.bmp', 'TRACTOR.bmp', 'TRUMPET.bmp', 'UMBRELLA.bmp', 'VASE.bmp', 'WATERING.bmp', 'WEATHERV.bmp', 'WELL.bmp', 'WHEEL.bmp', 'WHIP.bmp', 'WINDOW.bmp', 'WOLF.bmp', 'ZEBRA.bmp', 'ski.bmp']\n"
     ]
    }
   ],
   "source": [
    "# Create events\n",
    "events = {}\n",
    "\n",
    "for s in np.arange(n_subject):\n",
    "    events[s] = []\n",
    "    events[s].append(mne.events_from_annotations(raw[s][0]))\n",
    "    events[s].append(mne.events_from_annotations(raw[s][1]))\n",
    "\n",
    "# Reorder label\n",
    "for s in np.arange(n_subject):\n",
    "    for i in list(events[s][1][1].keys()):\n",
    "        events[s][1][1][i] = events[s][1][1][i] + 74\n",
    "\n",
    "# Creating dictionnary\n",
    "dict = events[0][0][1] | events[0][1][1]\n",
    "dict = {v: k for k, v in dict.items()}\n",
    "animal_values = [4,11,12,25,30,31,33,40,41,44,46,47,49,53,55,61,69,72,73,81,84,88,91,99,103,105,112,113,116,124,125,127,128,130,135,146,147]\n",
    "object_values = []\n",
    "for i in np.arange(1,149):\n",
    "    if (i not in animal_values):\n",
    "        object_values.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44285340-2ed2-410b-9d5c-6537044a319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animal class\n",
    "dict_animal = {}\n",
    "for i in dict.keys():\n",
    "    if (i in animal_values):\n",
    "        dict_animal[i] = dict[i]\n",
    "\n",
    "# Object class\n",
    "dict_object = {}\n",
    "for i in dict.keys():\n",
    "    if (i in object_values):\n",
    "        dict_object[i] = dict[i]\n",
    "\n",
    "# Classes\n",
    "classes = {\"Object\" : 0, \"Animal\" : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9921e3be-c0a0-47e9-9730-65f25d52bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten raw\n",
    "raw_flat = {}\n",
    "for s in np.arange(n_subject):\n",
    "    for k in [0,1]:\n",
    "         raw_flat[2*s+k] = raw[s][k]\n",
    "            \n",
    "events_flat = {}\n",
    "for s in np.arange(n_subject):\n",
    "    for k in [0,1]:\n",
    "         events_flat[2*s+k] = events[s][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f3b172-1f4e-4b67-81b0-551851d445ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels by class index\n",
    "def binary(events):\n",
    "\n",
    "    for i in np.arange(len(events[0][:,-1])):\n",
    "        if (events[0][:,-1][i] in dict_animal.keys()):\n",
    "            events[0][:,-1][i] = 1\n",
    "        else:\n",
    "            events[0][:,-1][i] = 0\n",
    "\n",
    "    return events\n",
    "\n",
    "events_binary = {}\n",
    "\n",
    "for s in np.arange(2*n_subject):\n",
    "    events_binary[s] = binary(events_flat[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87431c5-a538-4fe3-a073-9703bfd885e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.viz.plot_events(events_binary[0][0], event_id = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a25f049f-b504-4c16-83ef-edb4a6dba439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 74 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Creating epochs\n",
    "epochs = {}\n",
    "for s in np.arange(2*n_subject):\n",
    "    epochs[s] = mne.Epochs(raw_flat[s], events_binary[s][0], event_id=classes, preload=True, tmin = -1, tmax=2.5, baseline=(-1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73581cb1-243e-4390-98da-d572a9a19f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elec = len(epochs[0].ch_names)\n",
    "n_times = len(epochs[0].times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa37099a-63df-4af4-82c9-c5edc7ac5bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n",
      "(74, 256, 3501)\n"
     ]
    }
   ],
   "source": [
    "# 17 subject and 2 runs by subject\n",
    "n_subject = 34\n",
    "for s in np.arange(n_subject):\n",
    "    print(epochs[s].get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a215905c-74ab-4cac-b7af-73aa0323c402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2516, 256, 3501)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate EEG matrix\n",
    "epochs_data = {}\n",
    "for k in np.arange(n_subject):\n",
    "    epochs_data[k] = epochs[k].get_data()\n",
    "\n",
    "list_epochs = []\n",
    "for k in np.arange(n_subject):\n",
    "    list_epochs.append(epochs_data[k])\n",
    "\n",
    "power = np.concatenate(list_epochs, axis=0)\n",
    "n_times = power.shape[2]\n",
    "power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ded59d6-c79b-42d5-ad64-c1bffdcb758c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels, equals classes\n",
    "list_labels = []\n",
    "for s in np.arange(n_subject):\n",
    "    list_labels.append(events_binary[s][0][:,-1])\n",
    "    \n",
    "all_labels = np.concatenate(list_labels)\n",
    "n_1 = np.where(all_labels == 1)[0].shape[0]\n",
    "index_0 = np.where(all_labels == 0)[0][0:n_1]\n",
    "index_1 = np.where(all_labels == 1)[0]\n",
    "index_inputs = np.sort(np.concatenate([index_0,index_1]))\n",
    "labels_eq = all_labels[index_inputs]\n",
    "labels_eq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a019d9-312f-4d24-88ea-cce5b555a953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292, 256, 3501)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select inputs to equalize classes\n",
    "power = power[index_inputs]\n",
    "n_inputs = power.shape[0]\n",
    "power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c9ce846-f02f-45da-9e66-dacc370a72a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292, 22, 3501)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select same electrods than CM dataset\n",
    "elec_cm = ['F7', 'AFF5h','F3','AFP1','AFP2','AFF6h','F4','F8','AFF1h','AFF2h','FCz','Pz','FT7','C3','TP7','P3', 'POO1','POO2','P4','TP8','C4','FT8']\n",
    "list_elec_cm = []\n",
    "for i in np.arange(len(elec_cm)):\n",
    "    list_elec_cm.append(np.where(np.array(raw[0][0].ch_names) == elec_cm[i])[0][0])\n",
    "    \n",
    "n_elec = 22\n",
    "def select_cm(selection):\n",
    "    power_sel = np.empty((n_inputs, n_elec, n_times))\n",
    "    for l in np.arange(n_inputs):\n",
    "        for s in np.arange(n_elec):\n",
    "            power_sel[l][s] = power[l][selection[s]]\n",
    "    return power_sel\n",
    "\n",
    "power_cm = select_cm(list_elec_cm)\n",
    "power_cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d68fff26-c8d4-4adc-ba8a-b812ef941628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select D(E_k)\n",
    "def power_select(selection):\n",
    "    power_sel = np.empty((n_inputs, budget, n_times))\n",
    "    for l in np.arange(n_inputs):\n",
    "        for s in np.arange(budget):\n",
    "            power_sel[l][s] = power_cm[l][selection[s]]\n",
    "    return power_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e713e2-4cdb-4e41-86f5-81e7019a6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "# Sorted by maximum of variance\n",
    "import statistics as stats\n",
    "\n",
    "def var_select(budget):\n",
    "    \n",
    "    start = time.time()\n",
    "    inputs_1 = np.where(np.array(labels_eq) == 1)[0]\n",
    "    power_1 = np.swapaxes(power_zaineb[inputs_1], 0, 1)\n",
    "    power_1 = torch.Tensor(power_1)\n",
    "    power_1 = torch.flatten(power_1, start_dim=1, end_dim=2)\n",
    "    power_1 = np.array(power_1)\n",
    "    var_1 = np.var(power_1, axis=1)\n",
    "\n",
    "    var_sorted = np.flip(np.argsort(var_1))\n",
    "\n",
    "    x = var_sorted[0:budget]\n",
    "    end = time.time()\n",
    "    exe = end - start\n",
    "    print(f\"TIME : {exe}\")\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941480e-d3a4-4c8e-99d4-6f5a661da374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance matrix per epoch\n",
    "import scipy\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def calc_MI(x, y, bins=20):\n",
    "\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "\n",
    "    return mi\n",
    "\n",
    "def mat_MI(ID_inputs):\n",
    "\n",
    "    epoch = power_zaineb[ID_inputs]\n",
    "    mat = scipy.spatial.distance.pdist(epoch, calc_MI)\n",
    "    mat = scipy.spatial.distance.squareform(mat)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be25354-551f-44ba-bdfa-3a4fb0d8fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance matrix for MI\n",
    "start = time.time()\n",
    "for s in np.arange(n_inputs):\n",
    "    np.save(f\"MI_TD/mat_MI_TD_{s}\", mat_MI(s))\n",
    "end = time.time()\n",
    "exe = end - start\n",
    "print(f\"TIME : {exe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c33191-d085-4daf-8a14-bdf7d7f7f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load distance matrix\n",
    "dist_mat = {}\n",
    "for l in np.arange(n_inputs):\n",
    "    dist_mat[l] = np.load(f\"MI_TD/mat_MI_TD_{l}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102cdee-f1fb-439b-9b45-470ffa2c862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency matrix\n",
    "import networkx as nx\n",
    "def adj_matrix(dist_mat, seuil):\n",
    "\n",
    "    adj_mat = np.empty((n_elec, n_elec))\n",
    "\n",
    "    for i in np.arange(n_elec):\n",
    "        for j in np.arange(n_elec):\n",
    "            if (dist_mat[i][j] > seuil):\n",
    "                adj_mat[i][j] = 1\n",
    "            else:\n",
    "                adj_mat[i][j] = 0\n",
    "    return adj_mat\n",
    "\n",
    "adj_mat = {}\n",
    "G = {}\n",
    "s = 0.5\n",
    "\n",
    "for l in np.arange(n_inputs):\n",
    "    adj_mat[l] = adj_matrix(dist_mat[l], seuil = s)\n",
    "    adj_mat[l] = np.triu(adj_mat[l], k=1)\n",
    "    G[l] = nx.from_numpy_matrix(adj_mat[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716a512-b8ad-4b86-b17f-41084d14fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph degree\n",
    "def deg_max(G):\n",
    "    vect_deg = np.empty(n_elec)\n",
    "    for i, j in G.degree():\n",
    "        vect_deg[i] = int(j)\n",
    "\n",
    "    deg_max_G = int(vect_deg.max())\n",
    "    return deg_max_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93fee03-d1f6-4af4-8c45-d97cec4e3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score function\n",
    "def score(ID_inputs, G, V):\n",
    "    \n",
    "    epoch = power_zaineb[ID_inputs]\n",
    "\n",
    "    deg_max_G = deg_max(G)\n",
    "    vect_mi = np.empty(len(list(G.neighbors(V))))\n",
    "    score = 0\n",
    "\n",
    "    for i in np.arange(len(list(G.neighbors(V)))):\n",
    "        vect_mi[i] = calc_MI(epoch[V], epoch[list(G.neighbors(V))[i]])\n",
    "\n",
    "    w = np.empty(n_elec)\n",
    "    for i in np.arange(n_elec):\n",
    "        w[i] = epoch[i].mean()\n",
    "\n",
    "    w = abs(w)\n",
    "    w = w[list(G.neighbors(V))]\n",
    "\n",
    "    score = G.degree(V)*(vect_mi*w).sum()/deg_max_G\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e75dcd-8b4c-4470-bb1b-e8dfd6b42acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI method\n",
    "def selection(budget):\n",
    "\n",
    "    start = time.time()\n",
    "    vect_score_G = np.empty((n_inputs, n_elec))\n",
    "\n",
    "    for i in np.arange(n_inputs):\n",
    "        for j in np.arange(n_elec):\n",
    "            vect_score_G[i,j] = score(i, G[i], j)\n",
    "\n",
    "    mean_score = vect_score_G.mean(axis=0)\n",
    "    elec_sorted_G = np.flip(np.argsort(mean_score))\n",
    "    elec_selected_G = elec_sorted_G[0:budget]\n",
    "    end = time.time()\n",
    "    exe = end - start\n",
    "    print(f\"TIME : {exe}\")\n",
    "\n",
    "    return elec_selected_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb99ea-faa4-439a-a05c-4368ef3e9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means and MI\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_MI(budget, n_clusters):\n",
    "\n",
    "    start = time.time()\n",
    "    kmeans = {}\n",
    "    classes_kmeans = {}\n",
    "    \n",
    "    for l in np.arange(n_inputs):\n",
    "        list_classes = []\n",
    "        kmeans[l] = KMeans(n_clusters=n_clusters, random_state=0).fit(dist_mat[l])\n",
    "        for k in np.arange(n_clusters):\n",
    "            list_classes.append(np.where(kmeans[l].labels_ == k)[0])\n",
    "        classes_kmeans[l] = list_classes\n",
    "        \n",
    "    dict_score = {}\n",
    "    for l in np.arange(n_inputs):\n",
    "        vect_score = []\n",
    "        for k in np.arange(n_clusters):\n",
    "            list_score = []\n",
    "            for i in np.arange(len(classes_kmeans[l][k])):\n",
    "                list_score.append(score(l, G[l], classes_kmeans[l][k][i]))\n",
    "            vect_score.append(list_score)\n",
    "        dict_score[l] = vect_score\n",
    "        \n",
    "    rep = {}\n",
    "    for l in np.arange(n_inputs):\n",
    "        list_rep = []\n",
    "        for k in np.arange(n_clusters):\n",
    "            list_rep.append(classes_kmeans[l][k][np.where(dict_score[l][k] == np.array(dict_score[l][k]).max())][0])\n",
    "        rep[l] = list_rep\n",
    "        \n",
    "    mat_rep = np.empty((n_inputs, n_clusters))\n",
    "    for l in np.arange(n_inputs):\n",
    "        mat_rep[l] = rep[l]\n",
    "    mat_rep = mat_rep.astype('int')\n",
    "    \n",
    "    elec_sorted = np.flip(np.argsort(np.unique(mat_rep, return_counts=True)[1]))\n",
    "    elec_selected = elec_sorted[0:budget]\n",
    "    end = time.time()\n",
    "    exe = end - start\n",
    "    print(f\"TIME : {exe}\")\n",
    "    \n",
    "    return elec_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f8d3289-0251-4c87-b1a5-8126aaf3bc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292, 3, 3501)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget = 10\n",
    "\n",
    "# Variance\n",
    "#var_selection = var_select(budget=budget)\n",
    "# array([15, 19, 21,  5,  7, 12, 14,  0,  1,  4,  6,  3, 17, 20, 16,  9,  2, 8, 11, 13, 18, 10])\n",
    "\n",
    "# Tests\n",
    "# array([ 9, 11,  5,  4,  7,  0, 19, 18, 17, 16, 15, 14, 12, 13, 10,  6,  8, 1,  3,  2, 20, 21])\n",
    "\n",
    "# Learning\n",
    "# array([14,  4,  3, 11, 16,  2,  8, 10,  7,  9, 15,  5, 18,  1,  0,  6, 12, 13, 19, 17, 20, 21])\n",
    "\n",
    "# Hybrid\n",
    "# [1, 8, 21, 19, 6, 4, 9, 7, 16, 2]\n",
    "\n",
    "# MI\n",
    "#MI_selection = selection(budget)\n",
    "# array([5, 9, 4, 1, 6, 3, 8,  2, 21,  0])\n",
    "\n",
    "#K-means\n",
    "#selection_kmeans = kmeans_MI(budget=22, n_clusters=5)\n",
    "# array([ 9,  8, 17, 16,  5,  1,  4,  3,  2,  6, 12,  0, 14,  7, 11, 13, 21, 20, 18, 19, 10, 15])\n",
    "\n",
    "power_selection = power_select(selection)\n",
    "power_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95808cdc-4802-4333-bff0-c0c6031b808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualisation of electrods\n",
    "import plotly.express as px \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "montage = raw[0][0].get_montage()\n",
    "\n",
    "dict_loc = {}\n",
    "\n",
    "for i,j in montage.get_positions()['ch_pos'].items():\n",
    "    dict_loc[i] = j\n",
    "    \n",
    "elec_loc = np.empty((n_elec, 3))\n",
    "for i in np.arange(n_elec):\n",
    "    elec_loc[i] = dict_loc[elec_cm[i]]\n",
    "    \n",
    "def vis_elec(list_elec):\n",
    "\n",
    "    df_elec = pd.DataFrame(elec_loc, columns = ['x', 'y', 'z']) \n",
    "    selected = pd.DataFrame(index=np.arange(n_elec), columns=['Selected'])\n",
    "\n",
    "    for i in np.arange(n_elec):\n",
    "        if (i in list_elec):\n",
    "            selected['Selected'][i] = 'Yes'\n",
    "        else:\n",
    "            selected['Selected'][i] = 'No'\n",
    "\n",
    "    df_elec_selected = pd.concat([df_elec, selected], axis=1)\n",
    "\n",
    "    fig = px.scatter_3d(df_elec_selected, x = 'x', y = 'y',  z = 'z', opacity = 0.5, color=\"Selected\", title=f\"Topomap 3D of {len(list_elec)} best electrodes selected by score <br> with \" + f\"MI metric and threshold of 0.5\", color_discrete_map={'Yes' : 'red', 'No' : 'blue'})\n",
    "    fig.write_html(f\"subject_0_all_epoch_budget_{len(list_elec)}\"+\".html\")\n",
    "\n",
    "    return fig.show()\n",
    "\n",
    "vis_elec([ 9, 11,  5,  4,  7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5272a-17a1-4f41-8909-f2f748492ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrods selected\n",
    "np.array(elec_zaineb)[ np.array([9, 11,  5,  4,  7,  0, 19, 18, 17, 16])]\n",
    "# array(['AFF2h', 'Pz', 'AFF6h', 'AFP2', 'F8', 'F7', 'TP8', 'P4', 'POO2', 'POO1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d761d-db42-48c4-99ad-96c436383b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be7a31-da17-48c8-9983-79fae3ea8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y vector for binary cross entropy\n",
    "def labels_input(n_subject):\n",
    "\n",
    "    labels = {}\n",
    "    \n",
    "    for i in np.arange(n_inputs):\n",
    "        labels[f\"id_input_{i}\"] = labels_eq[i]\n",
    "        if (labels[f\"id_input_{i}\"] == 0):\n",
    "            labels[f\"id_input_{i}\"] = torch.tensor([1,0])\n",
    "        else:\n",
    "            labels[f\"id_input_{i}\"] = torch.tensor([0,1])\n",
    "    \n",
    "    return labels\n",
    "\n",
    "labels_inp = labels_input(n_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0e2e3-a585-4ddb-8778-b2d0cc8c0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, validation and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "ID = np.arange(n_inputs)\n",
    "ID_train, ID_val_test = train_test_split(ID, train_size=0.7, shuffle=True, random_state=37, stratify = labels_eq)\n",
    "ID_val, ID_test = train_test_split(ID_val_test, train_size=0.5, shuffle=True, random_state=37, stratify = labels_eq[ID_val_test])\n",
    "ID_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00ed70-174c-4719-bd2c-c5d2dc80ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "      'Characterizes a dataset for PyTorch'\n",
    "      def __init__(self, ID_pic, labels, stft_power):\n",
    "            'Initialization'\n",
    "            self.labels = labels\n",
    "            self.ID_pic = ID_pic\n",
    "            self.stft_power = stft_power\n",
    "\n",
    "      def __len__(self):\n",
    "            'Denotes the total number of samples'\n",
    "            return len(self.ID_pic)\n",
    "\n",
    "      def __getitem__(self, index):\n",
    "            'Generates one sample of data'\n",
    "            # Select sample\n",
    "            #ID = self.list_IDs[index]\n",
    "            ID = self.ID_pic[index]\n",
    "        \n",
    "            # Load data and get label\n",
    "            X = self.stft_power[ID]\n",
    "            y = self.labels[f\"id_input_{ID}\"]\n",
    "\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ea501-cd68-442e-a0c5-c34eb852fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and dataloader\n",
    "params = {'batch_size': 8, 'shuffle': True}\n",
    "\n",
    "train_set = Dataset(ID_train, labels_inp, power_selection)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, **params)\n",
    "\n",
    "val_set = Dataset(ID_val, labels_inp, power_selection)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_set, **params)\n",
    "\n",
    "test_set = Dataset(ID_test, labels_inp, power_selection)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab36795-b0bc-47c6-af83-7f7f69083552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPUs\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0718a7-b8b5-45a9-803a-3da778cb48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, pad1, pad2, pad3, pad4):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(2,2), padding=pad1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(2,2), padding=pad2)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(2,2), padding=pad3)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(2,2), padding=pad4)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(32)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(32)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(32)\n",
    "        self.BatchNorm4 = nn.BatchNorm2d(32)\n",
    "        # 32*436\n",
    "        self.fc1 = nn.Linear(32*436, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 20)\n",
    "        self.fc5 = nn.Linear(20, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.BatchNorm1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = self.BatchNorm2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "        x = self.BatchNorm3(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #print(x.shape)\n",
    "        x = self.BatchNorm4(x)\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Zero-padding\n",
    "if (budget in [1,2]):\n",
    "    cnn = CNN((4,1), (2,0), (1,0), (0,0))\n",
    "elif (budget in [3,4]):\n",
    "    cnn = CNN((3,1),(2,0), (1,0), (0,0))\n",
    "elif (budget in [5,6]):\n",
    "    cnn = CNN((2,1), (2,0), (1,0), (0,0))\n",
    "elif (budget in np.arange(7,13)):\n",
    "    cnn = CNN((1,1),  (2,0), (1,0), (0,0))\n",
    "elif (budget in np.arange(13,17)):\n",
    "    cnn = CNN((1,1),  (1,0), (1,0), (0,0))\n",
    "elif (budget in np.arange(17,23)):\n",
    "    cnn = CNN((1,1),  (1,0), (0,0), (0,0))\n",
    "\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2ce46-c5e2-42ed-ad0f-048502a8a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dimension to EEG matrix to have tensor of size (1, n_E, n_t)\n",
    "def correct_input(inputs):\n",
    "    inputs = np.array(inputs)\n",
    "    inputs = np.expand_dims(inputs, axis = 1)\n",
    "    inputs = torch.from_numpy(inputs)\n",
    "    inputs = inputs.float()\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e718ed-c7d1-4ec3-b8fa-20370aa71c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function for early stopping\n",
    "def validation(model, val_dataloader, loss_function):\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "\n",
    "    # Test validation data\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = correct_input(inputs)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss_total += loss.item()\n",
    "\n",
    "    return loss_total / len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130816fb-bae3-4b48-a925-11ba8067ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, epochs, optimizer, loss_function, train_dataloader, val_dataloader):\n",
    "\n",
    "    last_loss = 100\n",
    "    patience = 20\n",
    "    trigger_times = 0\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = correct_input(inputs)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.float()\n",
    "            #labels = torch.Tensor.cpu(labels)\n",
    "            labels = labels.float()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(loss)\n",
    "\n",
    "            # Show progress\n",
    "            running_loss += loss.item()\n",
    "            print('loss: {:.8}'.format(loss.item()))\n",
    "            if i % 5 == 0 or i == len(train_dataloader):\n",
    "                print('[{}/{}, {}/{}] loss: {:.8}'.format(epoch, epochs, i, len(train_dataloader), loss.item()))\n",
    "            print(\"running lose :\", running_loss)\n",
    "        loss_train.append(running_loss / len(train_dataloader))\n",
    "\n",
    "        # Early stopping\n",
    "        current_loss = validation(model, val_dataloader, loss_function)\n",
    "        print('The Current Loss:', current_loss)\n",
    "        loss_val.append(current_loss)\n",
    "\n",
    "        if current_loss > last_loss:\n",
    "            trigger_times += 1\n",
    "            print('Trigger Times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                return model\n",
    "\n",
    "        else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "        last_loss = current_loss\n",
    "        \n",
    "    #plt.plot(loss_train)\n",
    "    #plt.plot(loss_val)\n",
    "    return model, loss_train, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733539ec-6237-424f-bef1-9824dfa2a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    y_true = np.empty(0)\n",
    "    y_pred = np.empty(0)\n",
    "\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs = correct_input(inputs)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.float()\n",
    "            labels = torch.Tensor.cpu(labels)\n",
    "            classes = np.argmax(labels, axis=1)\n",
    "            \n",
    "            y_true = np.concatenate((y_true, classes))\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.Tensor.cpu(outputs)\n",
    "            outputs = outputs.detach().numpy()\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            predicted = np.argmax(outputs, axis=1)\n",
    "            \n",
    "            y_pred = np.concatenate((y_pred, predicted))\n",
    "            \n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        accuracy = (tn + tp) / (tn + fp + fn + tp) * 100\n",
    "        specificity = tn / (tn+fp) * 100\n",
    "        sensitivity = tp / (tp+fn) * 100\n",
    "        d = {'Vrai Animal': [tp, fn], 'Vrai Objet': [fp, tn]}\n",
    "        m_conf = pd.DataFrame(data=d, index=['Animal prédit', 'Objet prédit'])\n",
    "        \n",
    "    return accuracy, sensitivity, specificity, m_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f84312-b09d-47d4-b203-6c85fb87246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with several iteration\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "#torch.cuda.manual_seed(seed)\n",
    "#torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "n = 10\n",
    "list_acc = []\n",
    "list_sens = []\n",
    "list_spe = []\n",
    "list_conf = []\n",
    "i = 0\n",
    "\n",
    "start = time.time()\n",
    "while i < n:\n",
    "    \n",
    "    if (budget in [1,2]):\n",
    "        cnn = CNN((4,1), (2,0), (1,0), (0,0))\n",
    "    elif (budget in [3,4]):\n",
    "        cnn = CNN((3,1),(2,0), (1,0), (0,0))\n",
    "    elif (budget in [5,6]):\n",
    "        cnn = CNN((2,1), (2,0), (1,0), (0,0))\n",
    "    elif (budget in np.arange(7,13)):\n",
    "        cnn = CNN((1,1),  (2,0), (1,0), (0,0))\n",
    "    elif (budget in np.arange(13,17)):\n",
    "        cnn = CNN((1,1),  (1,0), (1,0), (0,0))\n",
    "    elif (budget in np.arange(17,23)):\n",
    "        cnn = CNN((1,1),  (1,0), (0,0), (0,0))\n",
    "\n",
    "    cnn = cnn.to(device)\n",
    "    \n",
    "    dataset = \"TD\"\n",
    "    criterion = nn.BCELoss()\n",
    "    lr = 0.001\n",
    "    it = 150\n",
    "    optimizer = optim.SGD(cnn.parameters(), lr=lr)\n",
    "    optimizer_RMS = optim.RMSprop(cnn.parameters(), lr=lr)\n",
    "    optimizer_adam = optim.Adam(cnn.parameters(), lr=lr)\n",
    "    cnn_train, loss_train, loss_val = train(cnn, it, optimizer, criterion, train_dataloader, val_dataloader)\n",
    "    acc, sens, spe, m_conf = test(cnn_train, test_dataloader)\n",
    "    list_acc.append(acc)\n",
    "    list_sens.append(sens)\n",
    "    list_spe.append(spe)\n",
    "    list_conf.append(m_conf)\n",
    "    i += 1\n",
    "    \n",
    "end = time.time()\n",
    "exe = end - start\n",
    "print(f\"Temps d'execution : {exe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb6d0b-e97b-4083-afa6-723b498340ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss train and loss validation, accuracy, sensitivity and specificity\n",
    "plt.figure(0)\n",
    "acc, sens, spe, m_conf = test(cnn_train, test_dataloader)\n",
    "plt.plot(loss_train, label=\"Erreur d'apprentissage\")\n",
    "plt.plot(loss_val, label=\"Erreur de validation\")\n",
    "plt.legend()\n",
    "plt.figtext(0.1, 0, f\"Accuracy : {acc} %\")\n",
    "plt.figtext(0.1, -0.05, f\"Sensitivité : {sens} %\")\n",
    "plt.figtext(0.1, -0.1, f\"Spécificité : {spe} %\")\n",
    "plt.figtext(0.1, -0.25, f\"         {m_conf}\".replace(\"55\", \"55    \").replace(\"Objet prédit\", \" Objet prédit\").replace(\"Animal prédit \", \"Animal prédit\").replace(\"42\", \"42    \"))\n",
    "plt.figtext(0.6, 0, f\"Jeu de données : {dataset}\")\n",
    "plt.figtext(0.6, -0.05, f\"Nombre d'entrées : {n_inputs}\")\n",
    "plt.figtext(0.6, -0.1, f\"Nombre d'itérations : {it}\")\n",
    "plt.figtext(0.6, -0.15, f\"Taille du batch : {params['batch_size']}\")\n",
    "plt.figtext(0.6, -0.2, f\"Budget d'électrodes : {budget}\")\n",
    "plt.figtext(0.6, -0.25, f\"Taux d'apprentissage : {lr}\")\n",
    "plt.savefig(f\"graph_{dataset}_lr_{lr}_batch_{params['batch_size']}_budget_{budget}.pdf\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fe798-3a48-4ec9-88bd-185215dcf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of accuracy\n",
    "np.array(list_acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433654e-b1fb-4775-9c53-12aea9562456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid method\n",
    "# Seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "#torch.cuda.manual_seed(seed)\n",
    "#torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def hybrid(budget, power):\n",
    "    \n",
    "    E = np.arange(n_elec)\n",
    "    E_k = [1, 8, 21, 19, 6, 4, 9, 7]\n",
    "\n",
    "    while len(E_k) < budget:\n",
    "        \n",
    "        start = time.time()\n",
    "        acc_min = 101\n",
    "        e_min = 30\n",
    "\n",
    "        for l in np.delete(E, E_k):\n",
    "\n",
    "            power_unif = power.copy()\n",
    "\n",
    "            for k in np.arange(n_inputs):\n",
    "                for j in E_k:\n",
    "                    power_unif[k][j] = np.random.uniform(power.min(), power.max(), n_times)\n",
    "\n",
    "            for k in np.arange(n_inputs):\n",
    "                power_unif[k][l] = np.random.uniform(power.min(), power.max(), n_times)\n",
    "\n",
    "            test_set = Dataset(ID_test, labels_inp, power_unif)\n",
    "            test_dataloader = torch.utils.data.DataLoader(test_set, **params)\n",
    "            acc, sens, spe, m_conf = test(cnn_train, test_dataloader)\n",
    "\n",
    "            if (acc < acc_min):\n",
    "                acc_min = acc\n",
    "                e_min = l\n",
    "        \n",
    "        E_k.append(e_min)\n",
    "\n",
    "        print(f\"LENGTH E_K : {len(E_k)}\")\n",
    "        print(E_k)\n",
    "        \n",
    "        end = time.time()\n",
    "        exe = end - start\n",
    "        print(f\"TIME : {exe}\")\n",
    "                \n",
    "    return E_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d7db4-a7cb-4d80-a07d-66a019e62b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_selected = hybrid(budget=10, power=power_selection)\n",
    "# [1, 8, 21, 19, 6, 4, 9, 7, 16, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6a84e-353f-4e69-9f29-2fc9b5cbcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning method\n",
    "import torch.optim as optim\n",
    "\n",
    "def selection_by_learning(budget, power, method):\n",
    "    \n",
    "    start = time.time()\n",
    "    vect_acc = np.empty((n_elec))\n",
    "    \n",
    "    for l in np.arange(n_elec):\n",
    "        power_unif = power.copy()\n",
    "        for k in np.arange(n_inputs):\n",
    "            if (method == 'unif'):\n",
    "                power_unif[k][l] = np.random.uniform(power.min(), power.max(), n_times)\n",
    "\n",
    "        cnn = CNN((1,1), (1,0), (0,0), (0,0))\n",
    "        cnn = cnn.to(device)\n",
    "\n",
    "        train_set = Dataset(ID_train, labels_inp, power_unif)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_set, **params)\n",
    "\n",
    "        val_set = Dataset(ID_val, labels_inp, power_unif)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_set, **params)\n",
    "\n",
    "        test_set = Dataset(ID_test, labels_inp, power_unif)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_set, **params)\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        lr = 0.001\n",
    "        optimizer = optim.SGD(cnn.parameters(), lr=lr) \n",
    "\n",
    "        cnn_train, loss_train, loss_val = train(cnn, 150, optimizer, criterion, train_dataloader, val_dataloader)\n",
    "        acc, sens, spe, m_conf = test(cnn_train, test_dataloader)\n",
    "\n",
    "        vect_acc[l] = acc\n",
    "        \n",
    "        print(f\"END TRAINING {l}\")\n",
    "    \n",
    "    elec_sorted = np.argsort(vect_acc)\n",
    "    elec_selected = elec_sorted[0:budget]\n",
    "    end = time.time()\n",
    "    exe = end - start\n",
    "    print(f\"TIME : {exe}\")\n",
    "    \n",
    "    return vect_acc, elec_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47452bb-aafc-4b2b-a560-74c01253413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect_acc, elec_selected = selection_by_learning(budget=22, power=power_selection, method='unif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24a49d-20d1-4ac0-b5c9-c71a8f44116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test method\n",
    "def selection_by_test(budget, power, it, method):\n",
    "    \n",
    "    start = time.time()\n",
    "    mat_acc = np.empty((n_elec, it))\n",
    "\n",
    "    if (method == 'unif'):\n",
    "        for l in np.arange(n_elec):\n",
    "            power_unif = power.copy()\n",
    "            for i in np.arange(it):\n",
    "                np.random.seed(i)\n",
    "                for k in np.arange(n_inputs):\n",
    "                    power_unif[k][l] = np.random.uniform(power.min(), power.max(), n_times)\n",
    "\n",
    "                test_set = Dataset(ID_test, labels_inp, power_unif)\n",
    "                test_dataloader = torch.utils.data.DataLoader(test_set, **params)\n",
    "                acc, sens, spe, m_conf = test(cnn_train, test_dataloader)\n",
    "                mat_acc[l,i] = acc\n",
    "                print(l,i)\n",
    "    \n",
    "    elec_sorted = np.argsort(np.mean(mat_acc, axis=1))\n",
    "    elec_selected = elec_sorted[0:budget]\n",
    "    end = time.time()\n",
    "    exe = end - start\n",
    "    print(f\"TIME : {exe}\")\n",
    "                \n",
    "    return mat_acc, power_unif, elec_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884832c-91fd-4cf9-af33-e2a4367651c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_acc, power_unif, elec_selected = selection_by_test(budget=22, power=power_selection, it=5, method='unif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
